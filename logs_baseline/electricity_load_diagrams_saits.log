2025-10-15 19:39:52 [INFO]: No given device, using default device: cuda
2025-10-15 19:39:52 [WARNING]: ‚ÄºÔ∏è saving_path not given. Model files and tensorboard file will not be saved.
2025-10-15 19:39:52 [INFO]: Using customized MAE as the training loss function.
2025-10-15 19:39:52 [INFO]: Using customized MSE as the validation metric function.
2025-10-15 19:39:52 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 2,966,192
2025-10-15 19:39:54 [INFO]: Epoch 001 - training loss (MAE): 0.9973, validation MSE: 3.1936
2025-10-15 19:39:55 [INFO]: Epoch 002 - training loss (MAE): 0.6773, validation MSE: 3.0487
2025-10-15 19:39:57 [INFO]: Epoch 003 - training loss (MAE): 0.6151, validation MSE: 2.9123
2025-10-15 19:39:58 [INFO]: Epoch 004 - training loss (MAE): 0.5824, validation MSE: 2.8645
2025-10-15 19:39:59 [INFO]: Epoch 005 - training loss (MAE): 0.5605, validation MSE: 2.8674
2025-10-15 19:40:00 [INFO]: Epoch 006 - training loss (MAE): 0.5431, validation MSE: 2.8387
2025-10-15 19:40:01 [INFO]: Epoch 007 - training loss (MAE): 0.5265, validation MSE: 2.8175
2025-10-15 19:40:02 [INFO]: Epoch 008 - training loss (MAE): 0.5188, validation MSE: 2.8211
2025-10-15 19:40:04 [INFO]: Epoch 009 - training loss (MAE): 0.5065, validation MSE: 2.8149
2025-10-15 19:40:05 [INFO]: Epoch 010 - training loss (MAE): 0.4999, validation MSE: 2.8139
2025-10-15 19:40:06 [INFO]: Epoch 011 - training loss (MAE): 0.4929, validation MSE: 2.8040
2025-10-15 19:40:07 [INFO]: Epoch 012 - training loss (MAE): 0.4875, validation MSE: 2.7955
2025-10-15 19:40:08 [INFO]: Epoch 013 - training loss (MAE): 0.4842, validation MSE: 2.7980
2025-10-15 19:40:09 [INFO]: Epoch 014 - training loss (MAE): 0.4812, validation MSE: 2.7960
2025-10-15 19:40:11 [INFO]: Epoch 015 - training loss (MAE): 0.4749, validation MSE: 2.7901
2025-10-15 19:40:12 [INFO]: Epoch 016 - training loss (MAE): 0.4699, validation MSE: 2.7845
2025-10-15 19:40:13 [INFO]: Epoch 017 - training loss (MAE): 0.4658, validation MSE: 2.7721
2025-10-15 19:40:14 [INFO]: Epoch 018 - training loss (MAE): 0.4655, validation MSE: 2.7745
2025-10-15 19:40:15 [INFO]: Epoch 019 - training loss (MAE): 0.4618, validation MSE: 2.7696
2025-10-15 19:40:16 [INFO]: Epoch 020 - training loss (MAE): 0.4569, validation MSE: 2.7642
2025-10-15 19:40:18 [INFO]: Epoch 021 - training loss (MAE): 0.4547, validation MSE: 2.7663
2025-10-15 19:40:19 [INFO]: Epoch 022 - training loss (MAE): 0.4511, validation MSE: 2.7560
2025-10-15 19:40:20 [INFO]: Epoch 023 - training loss (MAE): 0.4475, validation MSE: 2.7632
2025-10-15 19:40:21 [INFO]: Epoch 024 - training loss (MAE): 0.4461, validation MSE: 2.7485
2025-10-15 19:40:22 [INFO]: Epoch 025 - training loss (MAE): 0.4442, validation MSE: 2.7541
2025-10-15 19:40:24 [INFO]: Epoch 026 - training loss (MAE): 0.4415, validation MSE: 2.7464
2025-10-15 19:40:25 [INFO]: Epoch 027 - training loss (MAE): 0.4398, validation MSE: 2.7494
2025-10-15 19:40:26 [INFO]: Epoch 028 - training loss (MAE): 0.4394, validation MSE: 2.7297
2025-10-15 19:40:27 [INFO]: Epoch 029 - training loss (MAE): 0.4348, validation MSE: 2.7345
2025-10-15 19:40:28 [INFO]: Epoch 030 - training loss (MAE): 0.4314, validation MSE: 2.7330
2025-10-15 19:40:29 [INFO]: Epoch 031 - training loss (MAE): 0.4325, validation MSE: 2.7375
2025-10-15 19:40:31 [INFO]: Epoch 032 - training loss (MAE): 0.4307, validation MSE: 2.7335
2025-10-15 19:40:32 [INFO]: Epoch 033 - training loss (MAE): 0.4282, validation MSE: 2.7441
2025-10-15 19:40:33 [INFO]: Epoch 034 - training loss (MAE): 0.4283, validation MSE: 2.7446
2025-10-15 19:40:34 [INFO]: Epoch 035 - training loss (MAE): 0.4260, validation MSE: 2.7380
2025-10-15 19:40:35 [INFO]: Epoch 036 - training loss (MAE): 0.4222, validation MSE: 2.7241
2025-10-15 19:40:37 [INFO]: Epoch 037 - training loss (MAE): 0.4205, validation MSE: 2.7299
2025-10-15 19:40:38 [INFO]: Epoch 038 - training loss (MAE): 0.4197, validation MSE: 2.7257
2025-10-15 19:40:39 [INFO]: Epoch 039 - training loss (MAE): 0.4178, validation MSE: 2.7188
2025-10-15 19:40:40 [INFO]: Epoch 040 - training loss (MAE): 0.4158, validation MSE: 2.7287
2025-10-15 19:40:41 [INFO]: Epoch 041 - training loss (MAE): 0.4175, validation MSE: 2.7180
2025-10-15 19:40:43 [INFO]: Epoch 042 - training loss (MAE): 0.4191, validation MSE: 2.7127
2025-10-15 19:40:44 [INFO]: Epoch 043 - training loss (MAE): 0.4133, validation MSE: 2.7076
2025-10-15 19:40:45 [INFO]: Epoch 044 - training loss (MAE): 0.4106, validation MSE: 2.7061
2025-10-15 19:40:46 [INFO]: Epoch 045 - training loss (MAE): 0.4101, validation MSE: 2.7059
2025-10-15 19:40:47 [INFO]: Epoch 046 - training loss (MAE): 0.4101, validation MSE: 2.7094
2025-10-15 19:40:49 [INFO]: Epoch 047 - training loss (MAE): 0.4088, validation MSE: 2.7040
2025-10-15 19:40:50 [INFO]: Epoch 048 - training loss (MAE): 0.4078, validation MSE: 2.7075
2025-10-15 19:40:51 [INFO]: Epoch 049 - training loss (MAE): 0.4068, validation MSE: 2.7155
2025-10-15 19:40:52 [INFO]: Epoch 050 - training loss (MAE): 0.4051, validation MSE: 2.7243
2025-10-15 19:40:53 [INFO]: Epoch 051 - training loss (MAE): 0.4036, validation MSE: 2.7033
2025-10-15 19:40:54 [INFO]: Epoch 052 - training loss (MAE): 0.4027, validation MSE: 2.7011
2025-10-15 19:40:56 [INFO]: Epoch 053 - training loss (MAE): 0.4013, validation MSE: 2.6910
2025-10-15 19:40:57 [INFO]: Epoch 054 - training loss (MAE): 0.4015, validation MSE: 2.6790
2025-10-15 19:40:58 [INFO]: Epoch 055 - training loss (MAE): 0.3997, validation MSE: 2.6849
2025-10-15 19:40:59 [INFO]: Epoch 056 - training loss (MAE): 0.3988, validation MSE: 2.6862
2025-10-15 19:41:00 [INFO]: Epoch 057 - training loss (MAE): 0.3984, validation MSE: 2.6974
2025-10-15 19:41:02 [INFO]: Epoch 058 - training loss (MAE): 0.3991, validation MSE: 2.6814
2025-10-15 19:41:03 [INFO]: Epoch 059 - training loss (MAE): 0.3965, validation MSE: 2.6766
2025-10-15 19:41:04 [INFO]: Epoch 060 - training loss (MAE): 0.3963, validation MSE: 2.6725
2025-10-15 19:41:05 [INFO]: Epoch 061 - training loss (MAE): 0.3986, validation MSE: 2.6636
2025-10-15 19:41:06 [INFO]: Epoch 062 - training loss (MAE): 0.3970, validation MSE: 2.6668
2025-10-15 19:41:08 [INFO]: Epoch 063 - training loss (MAE): 0.3943, validation MSE: 2.6778
2025-10-15 19:41:09 [INFO]: Epoch 064 - training loss (MAE): 0.3937, validation MSE: 2.6746
2025-10-15 19:41:10 [INFO]: Epoch 065 - training loss (MAE): 0.3940, validation MSE: 2.6586
2025-10-15 19:41:11 [INFO]: Epoch 066 - training loss (MAE): 0.3904, validation MSE: 2.6565
2025-10-15 19:41:12 [INFO]: Epoch 067 - training loss (MAE): 0.3895, validation MSE: 2.6543
2025-10-15 19:41:14 [INFO]: Epoch 068 - training loss (MAE): 0.3890, validation MSE: 2.6644
2025-10-15 19:41:15 [INFO]: Epoch 069 - training loss (MAE): 0.3878, validation MSE: 2.6492
2025-10-15 19:41:16 [INFO]: Epoch 070 - training loss (MAE): 0.3874, validation MSE: 2.6516
2025-10-15 19:41:17 [INFO]: Epoch 071 - training loss (MAE): 0.3873, validation MSE: 2.6533
2025-10-15 19:41:18 [INFO]: Epoch 072 - training loss (MAE): 0.3872, validation MSE: 2.6464
2025-10-15 19:41:19 [INFO]: Epoch 073 - training loss (MAE): 0.3869, validation MSE: 2.6578
2025-10-15 19:41:21 [INFO]: Epoch 074 - training loss (MAE): 0.3851, validation MSE: 2.6494
2025-10-15 19:41:22 [INFO]: Epoch 075 - training loss (MAE): 0.3840, validation MSE: 2.6481
2025-10-15 19:41:23 [INFO]: Epoch 076 - training loss (MAE): 0.3838, validation MSE: 2.6519
2025-10-15 19:41:24 [INFO]: Epoch 077 - training loss (MAE): 0.3863, validation MSE: 2.6614
2025-10-15 19:41:25 [INFO]: Epoch 078 - training loss (MAE): 0.3840, validation MSE: 2.6535
2025-10-15 19:41:26 [INFO]: Epoch 079 - training loss (MAE): 0.3822, validation MSE: 2.6485
2025-10-15 19:41:28 [INFO]: Epoch 080 - training loss (MAE): 0.3825, validation MSE: 2.6506
2025-10-15 19:41:29 [INFO]: Epoch 081 - training loss (MAE): 0.3836, validation MSE: 2.6490
2025-10-15 19:41:30 [INFO]: Epoch 082 - training loss (MAE): 0.3811, validation MSE: 2.6554
2025-10-15 19:41:31 [INFO]: Epoch 083 - training loss (MAE): 0.3824, validation MSE: 2.6482
2025-10-15 19:41:32 [INFO]: Epoch 084 - training loss (MAE): 0.3805, validation MSE: 2.6627
2025-10-15 19:41:34 [INFO]: Epoch 085 - training loss (MAE): 0.3802, validation MSE: 2.6465
2025-10-15 19:41:35 [INFO]: Epoch 086 - training loss (MAE): 0.3790, validation MSE: 2.6556
2025-10-15 19:41:36 [INFO]: Epoch 087 - training loss (MAE): 0.3782, validation MSE: 2.6493
2025-10-15 19:41:37 [INFO]: Epoch 088 - training loss (MAE): 0.3773, validation MSE: 2.6447
2025-10-15 19:41:38 [INFO]: Epoch 089 - training loss (MAE): 0.3809, validation MSE: 2.6571
2025-10-15 19:41:39 [INFO]: Epoch 090 - training loss (MAE): 0.3774, validation MSE: 2.6487
2025-10-15 19:41:41 [INFO]: Epoch 091 - training loss (MAE): 0.3764, validation MSE: 2.6597
2025-10-15 19:41:42 [INFO]: Epoch 092 - training loss (MAE): 0.3757, validation MSE: 2.6604
2025-10-15 19:41:43 [INFO]: Epoch 093 - training loss (MAE): 0.3747, validation MSE: 2.6589
2025-10-15 19:41:44 [INFO]: Epoch 094 - training loss (MAE): 0.3750, validation MSE: 2.6673
2025-10-15 19:41:45 [INFO]: Epoch 095 - training loss (MAE): 0.3761, validation MSE: 2.6593
2025-10-15 19:41:47 [INFO]: Epoch 096 - training loss (MAE): 0.3742, validation MSE: 2.6602
2025-10-15 19:41:48 [INFO]: Epoch 097 - training loss (MAE): 0.3732, validation MSE: 2.6687
2025-10-15 19:41:49 [INFO]: Epoch 098 - training loss (MAE): 0.3736, validation MSE: 2.6631
2025-10-15 19:41:50 [INFO]: Epoch 099 - training loss (MAE): 0.3743, validation MSE: 2.6557
2025-10-15 19:41:51 [INFO]: Epoch 100 - training loss (MAE): 0.3733, validation MSE: 2.6494
2025-10-15 19:41:51 [INFO]: Finished training. The best model is from epoch#88.
[34m
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó
‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù    ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù   ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë
   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ñà‚ñà‚ïî‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë
   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë
   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ïê‚ïù ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë
   ‚ïö‚ïê‚ïù   ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

[SAITS][val ] {'MAE': 107.51917591282042, 'RMSE': 875.0471617173015, 'cov_90': None, 'cov_95': None, 'CRPS': None, 'sharpness': None}
Traceback (most recent call last):
  File "/media/usr/SSD/heeyoon/MASDE/scripts/baseline_run.py", line 74, in <module>
    main()
  File "/media/usr/SSD/heeyoon/MASDE/scripts/baseline_run.py", line 69, in main
    print(f"[{args.baseline.UPPER()}][test]", metrics["test"])  # NOTE: Python format bug, fix below
AttributeError: 'str' object has no attribute 'UPPER'
